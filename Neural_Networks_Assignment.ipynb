{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNidyfuKr9IDMLe+05j8g/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sobiii/Neural-Networks-CIFAR-10-Assignment/blob/main/Neural_Networks_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Reading CIFAR-10 and creating dataloaders (5%)\n",
        "\n"
      ],
      "metadata": {
        "id": "TNxFhE5_6bBb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3SiJ7sJ47XQ",
        "outputId": "d232cc28-c89b-4f6b-a2f7-d93983c76e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Setting up google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR-10 python dataset has been downloaded from the University of Toronto website."
      ],
      "metadata": {
        "id": "7yHlCmxFCtkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "# Defining data augmentation transformations\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.RandomRotation(15),\n",
        "     transforms.RandomVerticalFlip(),\n",
        "     transforms.RandomGrayscale(p=0.1),\n",
        "     transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Defining test data transformations\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Loading the CIFAR-10 dataset\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "# Creating dataloaders\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Defining class labels\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Accessing labels from dataloaders\n",
        "\n",
        "for images, labels in trainloader:\n",
        "    print(images.shape)  # shape of images batch \n",
        "    print(labels.shape)  # shape of labels batch \n",
        "    break  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P760iWWlK3M",
        "outputId": "8a1bfc67-fac8-4cf5-d0e5-cb72b876210c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Creating the model (40%)"
      ],
      "metadata": {
        "id": "ivapJfRWqlnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Note to self - these hyper parameter settings are important for fine tuning the model]"
      ],
      "metadata": {
        "id": "nuTzpXPbHdVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, num_conv_layers, num_classes, hidden_layers, hidden_units):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.mlp_layer = nn.Linear(in_channels, out_channels)  # MLP layer to compute 'a'\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        for _ in range(num_blocks):\n",
        "            for _ in range(num_conv_layers):\n",
        "                conv_layer = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "                self.conv_layers.append(conv_layer)\n",
        "            in_channels = out_channels  # Updating the number of input channels for the next block\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # SpatialAveragePooling\n",
        "\n",
        "        # The MLP Classifier\n",
        "\n",
        "        self.classifier = nn.Sequential()\n",
        "        if hidden_layers > 0:\n",
        "            self.classifier.add_module('hidden_layer_0', nn.Linear(out_channels, hidden_units))\n",
        "            self.classifier.add_module('relu_0', nn.ReLU(inplace=True))\n",
        "            for i in range(1, hidden_layers):\n",
        "                self.classifier.add_module(f'hidden_layer_{i}', nn.Linear(hidden_units, hidden_units))\n",
        "                self.classifier.add_module(f'relu_{i}', nn.ReLU(inplace=True))\n",
        "            self.classifier.add_module('output_layer', nn.Linear(hidden_units, num_classes))\n",
        "        else:\n",
        "            self.classifier.add_module('output_layer', nn.Linear(out_channels, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = self.mlp_layer(self.avg_pool(x).squeeze())  # Prediciting 'a' using the MLP layer\n",
        "        a_list = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "            a_list.append(x)\n",
        "        O = torch.sum(torch.stack(a_list, dim=1), dim=1)  # Combine outputs using sum along the stack dimension\n",
        "        f = self.avg_pool(O).squeeze()  # Calculating 'f' using SpatialAveragePooling\n",
        "        output = self.classifier(f)  # Passing 'f' to the MLP classifier\n",
        "        return output, a_list\n",
        "\n",
        "# Example model parameters:\n",
        "\n",
        "in_channels = 3  # Number of input channels (3 for RGB images)\n",
        "out_channels = 64  # Number of output channels [Can be fined tuned for model performance]\n",
        "num_blocks = 3  # Number of blocks in the backbone [Can be fined tuned for model performance]\n",
        "num_conv_layers = 2  # Number of convolutional layers per block (K) [Can be fined tuned for model performance]\n",
        "num_classes = 10  # Number of output classes for classification\n",
        "\n",
        "hidden_layers = 2  # Number of hidden layers in the MLP classifier [Can be fined tuned for model performance]\n",
        "hidden_units = 256  # Number of hidden units in each hidden layer of the MLP classifier [Can be fined tuned for model performance]\n",
        "\n",
        "\n",
        "# Printing the models architecture\n",
        "\n",
        "model = MyModel(in_channels, out_channels, num_blocks, num_conv_layers, num_classes, hidden_layers, hidden_units)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVXThXqFqa3H",
        "outputId": "87fb27d0-e58d-4dc5-a8e0-7a5a7d15c5a9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (mlp_layer): Linear(in_features=3, out_features=64, bias=True)\n",
            "  (conv_layers): ModuleList(\n",
            "    (0-5): 6 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (hidden_layer_0): Linear(in_features=64, out_features=256, bias=True)\n",
            "    (relu_0): ReLU(inplace=True)\n",
            "    (hidden_layer_1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (relu_1): ReLU(inplace=True)\n",
            "    (output_layer): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) Creating the loss and optimiser (5%)"
      ],
      "metadata": {
        "id": "3ag26WcbkcV9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YS0e0BMxkzRz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4UEGcUAln--"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGeJVqW4lnyu"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGsGA_31lno3"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) Training script (30%)"
      ],
      "metadata": {
        "id": "MR97YWtwlSuU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uE_sWnzkzO_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mipNIpsmlotC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCk8YaADlomD"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5) Final model accuracy (5%)"
      ],
      "metadata": {
        "id": "M0BV1a4BldNs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeZCwD4gkzD_"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0P3x2xbkzBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QL9zLdVaky-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_n6RyGMFgpuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}